# TaleWeaver

Generate captivating videos from text prompts using the power of Llama 3 (via Groq API) for narrative creation and Luma AI for video generation.

## ğŸ¥ Demo

Check out a sample video generated by our app:   

https://github.com/suryavanshi/taleweaver/assets/c8d9aa1e-8a71-48a7-a3cf-0ac8372b7626/combined_video1727570709.478855.mp4

## ğŸŒŸ Features

- ğŸ“ Generate three-part narratives based on user input using Llama 3
- ğŸ¥ Create unique videos for each part of the narrative with Luma AI
- ğŸ”€ Automatically combine the generated videos into a single cohesive piece
- ğŸ–¥ï¸ User-friendly Streamlit interface for easy interaction
- ğŸ­ Support for various input types: Mood, Historical Event, Dream, Tutorial, Product Description and more

## ğŸš€ Getting Started

### Prerequisites

- Python 3.7+
- Luma AI API key
- Groq API key (for Llama 3 access)

### Installation

1. Clone the repository:
   ```
   git clone https://github.com/yourusername/taleweaver.git
   cd taleweaver
   ```

2. Install the required packages:
   ```
   pip install -r requirements.txt
   ```

3. Set up your API keys as environment variables:
   ```
   export GROQ_API_KEY="your-groq-api-key"
   export LUMAAI_API_KEY="your-lumaai-api-key"
   ```

## ğŸ¬ Usage

1. Run the Streamlit app:
   ```
   streamlit run st_groq_luma.py
   ```

2. Open your web browser and navigate to the provided local URL (usually `http://localhost:8501`).

3. Choose an input type (Mood, Historical Event, Dream) from the dropdown menu.

4. Enter your prompt in the text area.

5. Click the "Generate Video" button and wait for the magic to happen!

6. View the generated narrative and the final combined video directly in the app.

## ğŸ› ï¸ How It Works

1. The user input is processed by the Llama 3 model to generate a three-part narrative.
2. Each part of the narrative is sent to Luma AI to generate a unique video segment.
3. The three video segments are downloaded and combined into a single video using MoviePy.
4. The final video is displayed in the Streamlit app for the user to enjoy.

## ğŸ“Š Example Use Cases

- Visualize historical events with animated storytelling
- Create mood-based ambient videos for relaxation or focus
- Bring dream sequences to life with AI-generated visuals
- Develop educational content with engaging visual narratives
- Prototype storyboards for filmmakers and content creators

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgements

- [Luma AI](https://lumalabs.ai/) for their powerful video generation API
- [Groq](https://groq.com/) for providing access to the Llama 3 language model

